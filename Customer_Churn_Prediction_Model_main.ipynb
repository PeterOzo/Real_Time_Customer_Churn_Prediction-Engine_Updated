{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Churn Prediction Model\n",
        "# Real-world dataset analysis w\n",
        "# Author: Peter Chika Ozo-ogueji (Data Scientist)\n",
        "# Tech Stack: Python, Scikit-learn, XGBoost, TensorFlow, Pandas"
      ],
      "metadata": {
        "id": "4JROsA5CmzM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr4NIq-wmygY",
        "outputId": "ba83220f-538e-409f-ac75-e226dbb242a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Environment setup complete! Fixed version ready.\n",
            "üìä Loading real-world customer churn dataset...\n",
            "‚úÖ Dataset loaded successfully!\n",
            "üìã Dataset shape: (7043, 21)\n",
            "üéØ Target variable: Churn (Yes/No)\n",
            "\n",
            "============================================================\n",
            "üìà INITIAL DATA EXPLORATION\n",
            "============================================================\n",
            "\n",
            "Target distribution:\n",
            "Churn\n",
            "No     5174\n",
            "Yes    1869\n",
            "Name: count, dtype: int64\n",
            "Churn rate: 26.54%\n",
            "\n",
            "Missing values:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "============================================================\n",
            "üîß DATA PREPROCESSING & FEATURE ENGINEERING\n",
            "============================================================\n",
            "üßπ Cleaning data...\n",
            "üé® Creating corrected features...\n",
            "‚úÖ features created successfully!\n",
            "\n",
            "============================================================\n",
            "ü§ñ FEATURE PREPROCESSING\n",
            "============================================================\n",
            "üìã Selected 25 features for modeling\n",
            "‚úÖ Feature matrix shape: (7043, 25)\n",
            "‚úÖ Target distribution: {0: 5174, 1: 1869}\n",
            "\n",
            "============================================================\n",
            "üéØ MODEL DEVELOPMENT & TRAINING\n",
            "============================================================\n",
            "üîπ Training set: 4225 samples\n",
            "üîπ Validation set: 1409 samples\n",
            "üîπ Test set: 1409 samples\n",
            "‚úÖ After moderate SMOTE - Training set: 5587 samples\n",
            "\n",
            "üå≤ Training Random Forest Classifier...\n",
            "‚úÖ Random Forest - ROC AUC: 0.8253\n",
            "\n",
            "üöÄ Training XGBoost Classifier...\n",
            "‚úÖ XGBoost - ROC AUC: 0.8315\n",
            "\n",
            "üß† Training CORRECTED Neural Network...\n",
            "‚úÖ Neural Network - ROC AUC: 0.8260\n",
            "\n",
            "============================================================\n",
            "üìä MODEL EVALUATION & COMPARISON\n",
            "============================================================\n",
            "\n",
            "üèÜ MODEL PERFORMANCE COMPARISON:\n",
            "==================================================\n",
            "            Model  Accuracy  ROC AUC  F1 Score  Precision  Recall\n",
            "1         XGBoost    0.7864   0.8315    0.5992     0.5968  0.6016\n",
            "2  Neural Network    0.7445   0.8260    0.6121     0.5126  0.7594\n",
            "0   Random Forest    0.7779   0.8253    0.5854     0.5801  0.5909\n",
            "\n",
            "üèÜ BEST PERFORMING MODEL: XGBoost\n",
            "‚úÖ Accuracy: 0.7864\n",
            "‚úÖ ROC AUC: 0.8315\n",
            "‚úÖ F1 Score: 0.5992\n",
            "\n",
            "============================================================\n",
            "üí∞ BUSINESS IMPACT ANALYSIS\n",
            "============================================================\n",
            "üìä CONFUSION MATRIX ANALYSIS:\n",
            "True Positives (Correctly identified churners): 225\n",
            "False Positives (Incorrectly identified churners): 152\n",
            "True Negatives (Correctly identified retained): 883\n",
            "False Negatives (Missed churners): 149\n",
            "\n",
            "üí∞ BUSINESS VALUE ANALYSIS:\n",
            "========================================\n",
            "Average Customer Value: $1,200\n",
            "Value saved from retention: $67,500\n",
            "Cost of retention campaigns: $18,850\n",
            "NET BUSINESS VALUE: $48,650\n",
            "Return on Investment (ROI): 158.1%\n",
            "\n",
            "============================================================\n",
            "üîç MODEL VALIDATION\n",
            "============================================================\n",
            "üìä CROSS-VALIDATION ANALYSIS:\n",
            "Mean ROC AUC: 0.8345\n",
            "Standard Deviation: 0.0107\n",
            "95% Confidence Interval: [0.8136, 0.8554]\n",
            "Model Stability: HIGH\n",
            "\n",
            "üîç TOP 10 FEATURE IMPORTANCES (XGBoost):\n",
            "==================================================\n",
            "Contract_encoded: 0.4658\n",
            "OnlineSecurity_encoded: 0.0572\n",
            "MonthToMonth: 0.0486\n",
            "AutoPay: 0.0397\n",
            "PaymentMethod_encoded: 0.0360\n",
            "TechSupport_encoded: 0.0352\n",
            "Dependents_encoded: 0.0321\n",
            "PhoneService_encoded: 0.0273\n",
            "OnlineBackup_encoded: 0.0242\n",
            "tenure: 0.0199\n",
            "\n",
            "============================================================\n",
            "üéØ ACTIONABLE RECOMMENDATIONS\n",
            "============================================================\n",
            "üíº STRATEGIC RECOMMENDATIONS:\n",
            "==============================\n",
            "\n",
            "1. üéØ IMMEDIATE ACTIONS:\n",
            "   ‚Ä¢ Target month-to-month contract customers for retention\n",
            "   ‚Ä¢ Offer automatic payment incentives\n",
            "   ‚Ä¢ Implement early customer engagement programs\n",
            "   ‚Ä¢ Focus on customers with low service adoption\n",
            "\n",
            "2. üí∞ REVENUE IMPACT:\n",
            "   ‚Ä¢ Deploy model to identify ~377 high-risk customers monthly\n",
            "   ‚Ä¢ Expected monthly value: $4,054\n",
            "   ‚Ä¢ ROI of 158.1% on retention campaigns\n",
            "\n",
            "3. üîß IMPLEMENTATION:\n",
            "   ‚Ä¢ Integrate model into CRM system\n",
            "   ‚Ä¢ Set up monthly scoring and alerts\n",
            "   ‚Ä¢ A/B test retention strategies\n",
            "   ‚Ä¢ Monitor model performance quarterly\n",
            "\n",
            "4. üìä MODEL MONITORING:\n",
            "   ‚Ä¢ Retrain if ROC AUC drops below 0.781\n",
            "   ‚Ä¢ Monitor feature drift and data quality\n",
            "   ‚Ä¢ Track business KPIs and campaign effectiveness\n",
            "\n",
            "============================================================\n",
            "üèÜ PROJECT SUMMARY\n",
            "============================================================\n",
            "üìã TECHNICAL ACHIEVEMENTS:\n",
            "=========================\n",
            "‚úÖ Achieved 78.6% accuracy with XGBoost\n",
            "‚úÖ ROC AUC score: 0.8315\n",
            "‚úÖ Processed 7043 real customer records\n",
            "‚úÖ Engineered 25 meaningful features\n",
            "‚úÖ Established realistic business value framework\n",
            "\n",
            "üéØ BUSINESS IMPACT:\n",
            "===============\n",
            "‚Ä¢ Monthly business value: $4,054\n",
            "‚Ä¢ Campaign ROI: 158.1%\n",
            "‚Ä¢ Model precision: 59.7%\n",
            "‚Ä¢ Model recall: 60.2%\n",
            "\n",
            "üîß KEY FIXES APPLIED:\n",
            "====================\n",
            "‚Ä¢ Simplified neural network architecture (fixed overfitting)\n",
            "‚Ä¢ Realistic business cost assumptions\n",
            "‚Ä¢ Proper cross-validation methodology\n",
            "‚Ä¢ Conservative performance estimates\n",
            "‚Ä¢ Professional code structure and documentation\n",
            "\n",
            "============================================================\n",
            "üöÄ PROJECT COMPLETE!\n",
            "============================================================\n",
            "Ready for production deployment with realistic expectations.\n"
          ]
        }
      ],
      "source": [
        "# Customer Churn Prediction Model\n",
        "# Real-world dataset analysis\n",
        "# Author: Peter Chika Ozo-ogueji (Data Scientist)\n",
        "# Tech Stack: Python, Scikit-learn, XGBoost, TensorFlow, Pandas\n",
        "\n",
        "\"\"\"\n",
        "üéØ PROJECT OVERVIEW - CORRECTED VERSION\n",
        "=========================================\n",
        "This project demonstrates advanced machine learning techniques for customer churn prediction.\n",
        "FIXES APPLIED:\n",
        "- Corrected neural network architecture\n",
        "- Realistic business assumptions\n",
        "- Proper cross-validation methodology\n",
        "- Accurate performance metrics\n",
        "- Professional code structure\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# 1. ENVIRONMENT SETUP & DATA IMPORT\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import precision_recall_curve, f1_score, accuracy_score, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "# Deep Learning with CORRECTED architecture\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üöÄ Environment setup complete! Fixed version ready.\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. DATA LOADING & INITIAL EXPLORATION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"üìä Loading real-world customer churn dataset...\")\n",
        "\n",
        "# Load real IBM Telco dataset (NOT synthetic)\n",
        "url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"üìã Dataset shape: {df.shape}\")\n",
        "print(f\"üéØ Target variable: Churn (Yes/No)\")\n",
        "\n",
        "# Initial data exploration\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìà INITIAL DATA EXPLORATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(df['Churn'].value_counts())\n",
        "print(f\"Churn rate: {df['Churn'].value_counts(normalize=True)['Yes']:.2%}\")\n",
        "\n",
        "print(f\"\\nMissing values:\")\n",
        "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# ============================================================================\n",
        "# 3. DATA PREPROCESSING & FEATURE ENGINEERING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîß DATA PREPROCESSING & FEATURE ENGINEERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a copy for processing\n",
        "df_processed = df.copy()\n",
        "\n",
        "print(\"üßπ Cleaning data...\")\n",
        "\n",
        "# FIXED: Proper handling of TotalCharges\n",
        "df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
        "# Fill missing values with 0 for new customers (more realistic assumption)\n",
        "df_processed['TotalCharges'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert target variable to binary\n",
        "df_processed['Churn'] = df_processed['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# CORRECTED Feature Engineering with realistic assumptions\n",
        "print(\"üé® Creating corrected features...\")\n",
        "\n",
        "# 1. Tenure categories (more business-realistic)\n",
        "df_processed['TenureGroup'] = pd.cut(df_processed['tenure'],\n",
        "                                   bins=[0, 6, 18, 36, 100],\n",
        "                                   labels=['New', 'Short', 'Medium', 'Long'])\n",
        "\n",
        "# 2. Service count (simplified and accurate)\n",
        "service_cols = ['PhoneService', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
        "               'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
        "\n",
        "df_processed['ServiceCount'] = 0\n",
        "for col in service_cols:\n",
        "    if col == 'PhoneService':\n",
        "        df_processed['ServiceCount'] += (df_processed[col] == 'Yes').astype(int)\n",
        "    elif col == 'InternetService':\n",
        "        df_processed['ServiceCount'] += (df_processed[col] != 'No').astype(int)\n",
        "    else:\n",
        "        df_processed['ServiceCount'] += (df_processed[col] == 'Yes').astype(int)\n",
        "\n",
        "# 3. Realistic financial metrics\n",
        "df_processed['AvgMonthlyCharges'] = np.where(df_processed['tenure'] > 0,\n",
        "                                           df_processed['TotalCharges'] / df_processed['tenure'],\n",
        "                                           df_processed['MonthlyCharges'])\n",
        "\n",
        "# 4. Payment and contract features\n",
        "df_processed['AutoPay'] = (df_processed['PaymentMethod'].isin([\n",
        "    'Bank transfer (automatic)', 'Credit card (automatic)'])).astype(int)\n",
        "\n",
        "df_processed['MonthToMonth'] = (df_processed['Contract'] == 'Month-to-month').astype(int)\n",
        "\n",
        "# 5. Security services indicator\n",
        "df_processed['HasSecurity'] = ((df_processed['OnlineSecurity'] == 'Yes') |\n",
        "                              (df_processed['OnlineBackup'] == 'Yes') |\n",
        "                              (df_processed['DeviceProtection'] == 'Yes')).astype(int)\n",
        "\n",
        "print(\"‚úÖ features created successfully!\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. FEATURE PREPROCESSING FOR MACHINE LEARNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ü§ñ FEATURE PREPROCESSING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Select features for modeling (reduced set for better performance)\n",
        "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
        "                       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
        "                       'PaperlessBilling', 'PaymentMethod', 'TenureGroup']\n",
        "\n",
        "numerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges',\n",
        "                     'ServiceCount', 'AvgMonthlyCharges', 'AutoPay', 'MonthToMonth', 'HasSecurity']\n",
        "\n",
        "# Encode categorical variables\n",
        "df_ml = df_processed.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for feature in categorical_features:\n",
        "    if feature in df_ml.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_ml[f'{feature}_encoded'] = le.fit_transform(df_ml[feature].astype(str))\n",
        "        label_encoders[feature] = le\n",
        "\n",
        "# Prepare feature matrix\n",
        "encoded_features = [f'{f}_encoded' for f in categorical_features if f in df_ml.columns]\n",
        "all_features = numerical_features + encoded_features\n",
        "feature_columns = [col for col in all_features if col in df_ml.columns]\n",
        "\n",
        "X = df_ml[feature_columns]\n",
        "y = df_ml['Churn']\n",
        "\n",
        "print(f\"üìã Selected {len(feature_columns)} features for modeling\")\n",
        "print(f\"‚úÖ Feature matrix shape: {X.shape}\")\n",
        "print(f\"‚úÖ Target distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. MODEL DEVELOPMENT & TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ MODEL DEVELOPMENT & TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
        "\n",
        "print(f\"üîπ Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"üîπ Validation set: {X_val.shape[0]} samples\")\n",
        "print(f\"üîπ Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Handle class imbalance with SMOTE (moderate approach)\n",
        "smote = SMOTE(random_state=42, sampling_strategy=0.8)  # Less aggressive balancing\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"‚úÖ After moderate SMOTE - Training set: {X_train_balanced.shape[0]} samples\")\n",
        "\n",
        "models_results = {}\n",
        "\n",
        "# ============================================================================\n",
        "# 5.1 RANDOM FOREST CLASSIFIER\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüå≤ Training Random Forest Classifier...\")\n",
        "\n",
        "# Simplified parameter grid for realistic training time\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 15, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "rf_grid.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "best_rf = rf_grid.best_estimator_\n",
        "rf_pred = best_rf.predict(X_test)\n",
        "rf_pred_proba = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "models_results['Random Forest'] = {\n",
        "    'model': best_rf,\n",
        "    'predictions': rf_pred,\n",
        "    'probabilities': rf_pred_proba,\n",
        "    'accuracy': accuracy_score(y_test, rf_pred),\n",
        "    'roc_auc': roc_auc_score(y_test, rf_pred_proba),\n",
        "    'f1': f1_score(y_test, rf_pred),\n",
        "    'precision': precision_score(y_test, rf_pred),\n",
        "    'recall': recall_score(y_test, rf_pred)\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Random Forest - ROC AUC: {models_results['Random Forest']['roc_auc']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5.2 XGBOOST CLASSIFIER\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüöÄ Training XGBoost Classifier...\")\n",
        "\n",
        "# Simplified XGBoost parameters\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 6],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "xgb_grid.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "best_xgb = xgb_grid.best_estimator_\n",
        "xgb_pred = best_xgb.predict(X_test)\n",
        "xgb_pred_proba = best_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "models_results['XGBoost'] = {\n",
        "    'model': best_xgb,\n",
        "    'predictions': xgb_pred,\n",
        "    'probabilities': xgb_pred_proba,\n",
        "    'accuracy': accuracy_score(y_test, xgb_pred),\n",
        "    'roc_auc': roc_auc_score(y_test, xgb_pred_proba),\n",
        "    'f1': f1_score(y_test, xgb_pred),\n",
        "    'precision': precision_score(y_test, xgb_pred),\n",
        "    'recall': recall_score(y_test, xgb_pred)\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ XGBoost - ROC AUC: {models_results['XGBoost']['roc_auc']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5.3 NEURAL NETWORK\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüß† Training CORRECTED Neural Network...\")\n",
        "\n",
        "# FIXED: Much simpler architecture to prevent overfitting\n",
        "def create_simple_neural_network(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_dim=input_dim),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # FIXED: Lower learning rate and proper compilation\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', 'AUC'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and train corrected neural network\n",
        "nn_model = create_simple_neural_network(X_train_scaled.shape[1])\n",
        "\n",
        "# FIXED: Proper early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
        "\n",
        "# FIXED: Scale the balanced data properly for neural network\n",
        "X_train_balanced_scaled = scaler.fit_transform(X_train_balanced)\n",
        "\n",
        "# Train with corrected parameters\n",
        "history = nn_model.fit(\n",
        "    X_train_balanced_scaled, y_train_balanced,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=50,  # FIXED: Reduced epochs\n",
        "    batch_size=64,  # FIXED: Larger batch size\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=0  # Reduced verbosity\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "nn_pred_proba = nn_model.predict(X_test_scaled, verbose=0).flatten()\n",
        "nn_pred = (nn_pred_proba > 0.5).astype(int)\n",
        "\n",
        "models_results['Neural Network'] = {\n",
        "    'model': nn_model,\n",
        "    'predictions': nn_pred,\n",
        "    'probabilities': nn_pred_proba,\n",
        "    'accuracy': accuracy_score(y_test, nn_pred),\n",
        "    'roc_auc': roc_auc_score(y_test, nn_pred_proba),\n",
        "    'f1': f1_score(y_test, nn_pred),\n",
        "    'precision': precision_score(y_test, nn_pred),\n",
        "    'recall': recall_score(y_test, nn_pred)\n",
        "}\n",
        "\n",
        "print(f\"‚úÖ Neural Network - ROC AUC: {models_results['Neural Network']['roc_auc']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. MODEL EVALUATION & COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä MODEL EVALUATION & COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create comparison dataframe\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(models_results.keys()),\n",
        "    'Accuracy': [models_results[model]['accuracy'] for model in models_results.keys()],\n",
        "    'ROC AUC': [models_results[model]['roc_auc'] for model in models_results.keys()],\n",
        "    'F1 Score': [models_results[model]['f1'] for model in models_results.keys()],\n",
        "    'Precision': [models_results[model]['precision'] for model in models_results.keys()],\n",
        "    'Recall': [models_results[model]['recall'] for model in models_results.keys()]\n",
        "})\n",
        "\n",
        "comparison_df = comparison_df.sort_values('ROC AUC', ascending=False)\n",
        "print(\"\\nüèÜ MODEL PERFORMANCE COMPARISON:\")\n",
        "print(\"=\"*50)\n",
        "print(comparison_df.round(4))\n",
        "\n",
        "# Select best model\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_model = models_results[best_model_name]['model']\n",
        "\n",
        "print(f\"\\nüèÜ BEST PERFORMING MODEL: {best_model_name}\")\n",
        "print(f\"‚úÖ Accuracy: {models_results[best_model_name]['accuracy']:.4f}\")\n",
        "print(f\"‚úÖ ROC AUC: {models_results[best_model_name]['roc_auc']:.4f}\")\n",
        "print(f\"‚úÖ F1 Score: {models_results[best_model_name]['f1']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 7. BUSINESS IMPACT ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí∞ BUSINESS IMPACT ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Business assumptions\n",
        "avg_customer_value = 1200  # Realistic annual customer value\n",
        "retention_cost = 50       # Realistic retention campaign cost\n",
        "acquisition_cost = 200    # Realistic acquisition cost\n",
        "successful_retention_rate = 0.25  # Conservative 25% success rate\n",
        "\n",
        "# Calculate business metrics with best model\n",
        "best_predictions = models_results[best_model_name]['probabilities']\n",
        "threshold = 0.5\n",
        "\n",
        "# Confusion matrix components\n",
        "tp = np.sum((best_predictions >= threshold) & (y_test == 1))\n",
        "fp = np.sum((best_predictions >= threshold) & (y_test == 0))\n",
        "tn = np.sum((best_predictions < threshold) & (y_test == 0))\n",
        "fn = np.sum((best_predictions < threshold) & (y_test == 1))\n",
        "\n",
        "print(f\"üìä CONFUSION MATRIX ANALYSIS:\")\n",
        "print(f\"True Positives (Correctly identified churners): {tp}\")\n",
        "print(f\"False Positives (Incorrectly identified churners): {fp}\")\n",
        "print(f\"True Negatives (Correctly identified retained): {tn}\")\n",
        "print(f\"False Negatives (Missed churners): {fn}\")\n",
        "\n",
        "# Business value calculation\n",
        "value_saved_from_retention = tp * successful_retention_rate * avg_customer_value\n",
        "cost_of_campaigns = (tp + fp) * retention_cost\n",
        "cost_of_missed_churners = fn * avg_customer_value * 0.3  # Only count partial loss\n",
        "\n",
        "net_business_value = value_saved_from_retention - cost_of_campaigns\n",
        "\n",
        "print(f\"\\nüí∞ BUSINESS VALUE ANALYSIS:\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Average Customer Value: ${avg_customer_value:,.0f}\")\n",
        "print(f\"Value saved from retention: ${value_saved_from_retention:,.0f}\")\n",
        "print(f\"Cost of retention campaigns: ${cost_of_campaigns:,.0f}\")\n",
        "print(f\"NET BUSINESS VALUE: ${net_business_value:,.0f}\")\n",
        "\n",
        "# ROI calculation\n",
        "roi = ((net_business_value - cost_of_campaigns) / cost_of_campaigns) * 100 if cost_of_campaigns > 0 else 0\n",
        "print(f\"Return on Investment (ROI): {roi:.1f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8.CROSS-VALIDATION & STABILITY ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîç MODEL VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# FIXED: Proper cross-validation on original training data (not SMOTE'd)\n",
        "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "\n",
        "print(f\"üìä CROSS-VALIDATION ANALYSIS:\")\n",
        "print(f\"Mean ROC AUC: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "print(f\"95% Confidence Interval: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, {cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")\n",
        "\n",
        "# FIXED: Realistic stability assessment\n",
        "if cv_scores.std() < 0.02:\n",
        "    stability = \"HIGH\"\n",
        "elif cv_scores.std() < 0.05:\n",
        "    stability = \"MODERATE\"\n",
        "else:\n",
        "    stability = \"LOW\"\n",
        "\n",
        "print(f\"Model Stability: {stability}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 9. FEATURE IMPORTANCE ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    print(f\"\\nüîç TOP 10 FEATURE IMPORTANCES ({best_model_name}):\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': feature_columns,\n",
        "        'importance': best_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    for i, row in feature_importance.head(10).iterrows():\n",
        "        print(f\"{row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 10. ACTIONABLE RECOMMENDATIONS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ ACTIONABLE RECOMMENDATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"üíº STRATEGIC RECOMMENDATIONS:\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "print(\"\\n1. üéØ IMMEDIATE ACTIONS:\")\n",
        "print(\"   ‚Ä¢ Target month-to-month contract customers for retention\")\n",
        "print(\"   ‚Ä¢ Offer automatic payment incentives\")\n",
        "print(\"   ‚Ä¢ Implement early customer engagement programs\")\n",
        "print(\"   ‚Ä¢ Focus on customers with low service adoption\")\n",
        "\n",
        "print(\"\\n2. üí∞ REVENUE IMPACT:\")\n",
        "print(f\"   ‚Ä¢ Deploy model to identify ~{int(tp+fp)} high-risk customers monthly\")\n",
        "print(f\"   ‚Ä¢ Expected monthly value: ${net_business_value/12:,.0f}\")\n",
        "print(f\"   ‚Ä¢ ROI of {roi:.1f}% on retention campaigns\")\n",
        "\n",
        "print(\"\\n3. üîß IMPLEMENTATION:\")\n",
        "print(\"   ‚Ä¢ Integrate model into CRM system\")\n",
        "print(\"   ‚Ä¢ Set up monthly scoring and alerts\")\n",
        "print(\"   ‚Ä¢ A/B test retention strategies\")\n",
        "print(\"   ‚Ä¢ Monitor model performance quarterly\")\n",
        "\n",
        "print(\"\\n4. üìä MODEL MONITORING:\")\n",
        "print(f\"   ‚Ä¢ Retrain if ROC AUC drops below {models_results[best_model_name]['roc_auc'] - 0.05:.3f}\")\n",
        "print(\"   ‚Ä¢ Monitor feature drift and data quality\")\n",
        "print(\"   ‚Ä¢ Track business KPIs and campaign effectiveness\")\n",
        "\n",
        "# ============================================================================\n",
        "# 11. PROJECT SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÜ PROJECT SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"üìã TECHNICAL ACHIEVEMENTS:\")\n",
        "print(\"=\"*25)\n",
        "print(f\"‚úÖ Achieved {models_results[best_model_name]['accuracy']:.1%} accuracy with {best_model_name}\")\n",
        "print(f\"‚úÖ ROC AUC score: {models_results[best_model_name]['roc_auc']:.4f}\")\n",
        "print(f\"‚úÖ Processed {len(df)} real customer records\")\n",
        "print(f\"‚úÖ Engineered {len(feature_columns)} meaningful features\")\n",
        "print(f\"‚úÖ Established realistic business value framework\")\n",
        "\n",
        "print(f\"\\nüéØ BUSINESS IMPACT:\")\n",
        "print(\"=\"*15)\n",
        "print(f\"‚Ä¢ Monthly business value: ${net_business_value/12:,.0f}\")\n",
        "print(f\"‚Ä¢ Campaign ROI: {roi:.1f}%\")\n",
        "print(f\"‚Ä¢ Model precision: {models_results[best_model_name]['precision']:.1%}\")\n",
        "print(f\"‚Ä¢ Model recall: {models_results[best_model_name]['recall']:.1%}\")\n",
        "\n",
        "print(f\"\\nüîß KEY FIXES APPLIED:\")\n",
        "print(\"=\"*20)\n",
        "print(\"‚Ä¢ Simplified neural network architecture (fixed overfitting)\")\n",
        "print(\"‚Ä¢ Realistic business cost assumptions\")\n",
        "print(\"‚Ä¢ Proper cross-validation methodology\")\n",
        "print(\"‚Ä¢ Conservative performance estimates\")\n",
        "print(\"‚Ä¢ Professional code structure and documentation\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ PROJECT COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Ready for production deployment with realistic expectations.\")"
      ]
    }
  ]
}